{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f34a24d0",
   "metadata": {},
   "source": [
    "# Part 2 : Dashboard for surfers ! \n",
    "---\n",
    "Autors: MISSONGO Aim√© Blanchard & Hippolyte SODJINOU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762812b8",
   "metadata": {},
   "source": [
    "## 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e10d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependance\n",
    "#! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "79805077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da6f2ce",
   "metadata": {},
   "source": [
    "## 2) Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9ec66f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_scap(url):\n",
    "    response  = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    print(\"Connection OK\")\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    tables = soup.find_all(\"div\", class_=\"forecast-tab\")\n",
    "    lines = soup.find_all('div', class_='line')\n",
    "    # It is this list of dictionaries that will contain everything\n",
    "    all_data = []\n",
    "\n",
    "    for table in tables:\n",
    "        # 1. Day recovery (e.g., \"Friday, January 9\")\n",
    "        title_div = table.find(\"div\", class_=re.compile(\"title\"))\n",
    "        day = title_div.get_text(strip=True) if title_div else \"Inconnu\"\n",
    "\n",
    "        # 2. Retrieving data rows (skipping the header)\n",
    "        lines = table.find_all(\"div\", class_=\"line\")[1:]\n",
    "\n",
    "        for line in lines:\n",
    "            cells = line.find_all(\"div\", class_=re.compile(\"cell\"))\n",
    "            if len(cells) < 5:\n",
    "                continue\n",
    "\n",
    "            # Time extraction\n",
    "            hour = cells[0].get_text(strip=True)\n",
    "\n",
    "            # Wave extraction\n",
    "            wave = cells[2].get_text(strip=True)\n",
    "\n",
    "            # Extraction of wind direction (via the image's alt attribute)\n",
    "            direction_div = line.find(\"div\", class_=re.compile(r\"wind.*img\"))\n",
    "            direction = None\n",
    "            if direction_div:\n",
    "                img = direction_div.find(\"img\")\n",
    "                if img:\n",
    "                    direction = img.get(\"alt\")\n",
    "\n",
    "            # Wind speed extraction\n",
    "            speed_div = line.find(\"div\", class_=re.compile(\"large-bis-bis\"))\n",
    "            speed = speed_div.get_text(strip=True) if speed_div else \"N/C\"\n",
    "\n",
    "            # --- ASSOCIATION: We are creating a dictionary for this line ---\n",
    "            row = {\n",
    "                \"Jour\": day,\n",
    "                \"Heure\": hour,\n",
    "                \"Taille Vagues\": wave,\n",
    "                \"Vitesse Vent(km/h)\": speed,\n",
    "                \"Direction Vent\": direction\n",
    "            }\n",
    "            \n",
    "            # We add this line to our global list\n",
    "            all_data.append(row)\n",
    "\n",
    "    # --- CONVERSION TO DATAFRAME ---\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "26d00b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection OK\n"
     ]
    }
   ],
   "source": [
    "url = \"https://www.surf-report.com/meteo-surf/lacanau-s1043.html\"\n",
    "\n",
    "data = web_scap(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "48efbaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results\n",
    "#print(data.head())\n",
    "\n",
    "# Save in csv\n",
    "data.to_csv(\"meteo_surf.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9a45b50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42 entries, 0 to 41\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Jour                42 non-null     object\n",
      " 1   Heure               42 non-null     object\n",
      " 2   Taille Vagues       42 non-null     object\n",
      " 3   Vitesse Vent(km/h)  42 non-null     object\n",
      " 4   Direction Vent      42 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# data.head(20)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "7cc10c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jour</th>\n",
       "      <th>Heure</th>\n",
       "      <th>Taille Vagues</th>\n",
       "      <th>Vitesse Vent(km/h)</th>\n",
       "      <th>Direction Vent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vendredi 9 Janvier</td>\n",
       "      <td>06:00</td>\n",
       "      <td>5.0-7.6</td>\n",
       "      <td>51</td>\n",
       "      <td>Orientation vent Ouest Nord Ouest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vendredi 9 Janvier</td>\n",
       "      <td>09:00</td>\n",
       "      <td>5.3-8.0</td>\n",
       "      <td>54</td>\n",
       "      <td>Orientation vent Ouest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vendredi 9 Janvier</td>\n",
       "      <td>12:00</td>\n",
       "      <td>5.6-8.4</td>\n",
       "      <td>60</td>\n",
       "      <td>Orientation vent Ouest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vendredi 9 Janvier</td>\n",
       "      <td>15:00</td>\n",
       "      <td>5.5-8.2</td>\n",
       "      <td>56</td>\n",
       "      <td>Orientation vent Ouest Nord Ouest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vendredi 9 Janvier</td>\n",
       "      <td>18:00</td>\n",
       "      <td>5.1-7.6</td>\n",
       "      <td>49</td>\n",
       "      <td>Orientation vent Nord Ouest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Jour  Heure Taille Vagues Vitesse Vent(km/h)  \\\n",
       "0  Vendredi 9 Janvier  06:00       5.0-7.6                 51   \n",
       "1  Vendredi 9 Janvier  09:00       5.3-8.0                 54   \n",
       "2  Vendredi 9 Janvier  12:00       5.6-8.4                 60   \n",
       "3  Vendredi 9 Janvier  15:00       5.5-8.2                 56   \n",
       "4  Vendredi 9 Janvier  18:00       5.1-7.6                 49   \n",
       "\n",
       "                      Direction Vent  \n",
       "0  Orientation vent Ouest Nord Ouest  \n",
       "1             Orientation vent Ouest  \n",
       "2             Orientation vent Ouest  \n",
       "3  Orientation vent Ouest Nord Ouest  \n",
       "4        Orientation vent Nord Ouest  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4103fcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surf-scrap-hp\n",
      "  Using cached surf_scrap_hp-0.0.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\sodji\\anaconda3\\envs\\predictad_venv\\lib\\site-packages (from surf-scrap-hp) (2.32.5)\n",
      "Collecting beautifulsoup4 (from surf-scrap-hp)\n",
      "  Using cached beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting lxml (from surf-scrap-hp)\n",
      "  Downloading lxml-6.0.2-cp312-cp312-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\sodji\\anaconda3\\envs\\predictad_venv\\lib\\site-packages (from surf-scrap-hp) (2.3.3)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4->surf-scrap-hp)\n",
      "  Using cached soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sodji\\anaconda3\\envs\\predictad_venv\\lib\\site-packages (from beautifulsoup4->surf-scrap-hp) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\sodji\\anaconda3\\envs\\predictad_venv\\lib\\site-packages (from pandas->surf-scrap-hp) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sodji\\anaconda3\\envs\\predictad_venv\\lib\\site-packages (from pandas->surf-scrap-hp) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sodji\\anaconda3\\envs\\predictad_venv\\lib\\site-packages (from pandas->surf-scrap-hp) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sodji\\anaconda3\\envs\\predictad_venv\\lib\\site-packages (from pandas->surf-scrap-hp) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sodji\\anaconda3\\envs\\predictad_venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->surf-scrap-hp) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sodji\\anaconda3\\envs\\predictad_venv\\lib\\site-packages (from requests->surf-scrap-hp) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sodji\\anaconda3\\envs\\predictad_venv\\lib\\site-packages (from requests->surf-scrap-hp) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sodji\\anaconda3\\envs\\predictad_venv\\lib\\site-packages (from requests->surf-scrap-hp) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sodji\\anaconda3\\envs\\predictad_venv\\lib\\site-packages (from requests->surf-scrap-hp) (2025.10.5)\n",
      "Using cached surf_scrap_hp-0.0.2-py3-none-any.whl (4.6 kB)\n",
      "Using cached beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Using cached soupsieve-2.8.1-py3-none-any.whl (36 kB)\n",
      "Downloading lxml-6.0.2-cp312-cp312-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 15.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.0/4.0 MB 15.0 MB/s  0:00:00\n",
      "Installing collected packages: soupsieve, lxml, beautifulsoup4, surf-scrap-hp\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   ---------- ----------------------------- 1/4 [lxml]\n",
      "   -------------------- ------------------- 2/4 [beautifulsoup4]\n",
      "   ---------------------------------------- 4/4 [surf-scrap-hp]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.14.3 lxml-6.0.2 soupsieve-2.8.1 surf-scrap-hp-0.0.2\n"
     ]
    }
   ],
   "source": [
    "! pip install surf-scrap-hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a356f0b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surf_scrap_hp'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msurf_scrap_hp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m scrape_surf_report\n\u001b[32m      3\u001b[39m scrape_surf_report(\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttps://www.surf-report.com/meteo-surf/carcans-plage-s1013.html\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcarcans.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'surf_scrap_hp'"
     ]
    }
   ],
   "source": [
    "from surf_scrap_hp import scrape_surf_report\n",
    "\n",
    "scrape_surf_report(\n",
    "    \"https://www.surf-report.com/meteo-surf/carcans-plage-s1013.html\",\n",
    "    \"carcans.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predictad_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
